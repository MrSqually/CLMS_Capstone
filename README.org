#+title: Exploring the Relationship Between Domain and Hallucination Resolution Methodologies within LLM QA Systems.

* Methodology
- Generate several topic-based "domains" across subsets of popular QA datasets.
- Gauge the performance of open-domain LLM-based chat models against proper QA systems
- touch on retrieval and calibration methods against this baseline

* Datasets
- Topic Segmented (Science, Law, Rhetoric / Composition, more)
- "Factoid" vs "Synthesis" question types
  - sliding scale?
  - general idea: "synthesis questions require an understanding of what the semantic similarity between features encodes - i.e., an understanding of why attention weights are high".


* Models
** GPT-4
** [high-level / off-shelf general purpose Retrieval QA system]
** [high-level / off-shelf general purpose KG QA system]
** BERT-Tuned QA System (my IE final project)


* Benchmarks
** HaluEval
** MRR
** F1 (knowledgeF1 and rareF1)
** Etc.

* Retrieval / Calibration methods
** Path Grounding
** Response tuning via prompt
